{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio Demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q gradio==3.23.0\n",
    "# !pip install -q sentence_transformers\n",
    "# !pip install -U typing_extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "import gradio as gr\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import joblib\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO 1 - Category Clustering / Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/distilbert_sa_20241017_211535\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=3).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer model in Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model in eval mode\n",
    "model.eval()\n",
    "\n",
    "# Define sentiment labels\n",
    "sentiment_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "\n",
    "# Define function for prediction\n",
    "def predict_sentiment(review_text):\n",
    "    # Tokenize and predict on input text\n",
    "    encodings = tokenizer(review_text, truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\").to(device)\n",
    "    outputs = model(**encodings)\n",
    "    \n",
    "    # Calculate probabilities with softmax\n",
    "    probabilities = softmax(outputs.logits, dim=1).squeeze().tolist()\n",
    "    # Get the predicted class index\n",
    "    predicted_class = torch.argmax(outputs.logits).item()\n",
    "    \n",
    "    # Return both the predicted sentiment and probabilities as a dictionary\n",
    "    return {label: prob for label, prob in zip(sentiment_labels, probabilities)}\n",
    "\n",
    "# Create Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=predict_sentiment,\n",
    "    inputs=gr.Textbox(label=\"Enter a Review\"),\n",
    "    outputs=gr.Label(num_top_classes=3, label=\"Sentiment Probabilities\"),\n",
    "    title=\"Sentiment Analysis with DistilBERT\",\n",
    "    description=\"Enter a review to get a sentiment prediction with class probabilities displayed as a bar graph.\"\n",
    ")\n",
    "\n",
    "# Launch the demo\n",
    "interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO 2 - Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained transformer model and tokenizer\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Load trained KMeans model\n",
    "model_path = \"pickle/KMeans_clustering_model.pkl\"\n",
    "kmeans_model = joblib.load(model_path)\n",
    "\n",
    "# Define categories (adjust as per your clustering categories)\n",
    "category_names = {\n",
    "    0: \"Electronics & Media\",\n",
    "    1: \"Tablets & eReaders\",\n",
    "    2: \"Accessories & Adapters\",\n",
    "    3: \"Home & Smart Devices\",\n",
    "    4: \"Pet Supplies\",\n",
    "    5: \"Video & Streaming\"\n",
    "}\n",
    "\n",
    "# Function to generate embeddings and get the cluster\n",
    "def get_category(review_text):\n",
    "    # Encode the new review using the SentenceTransformer model\n",
    "    review_embedding = model.encode([review_text])\n",
    "    \n",
    "    # Predict the cluster\n",
    "    cluster_label = kmeans_model.predict(review_embedding)[0]\n",
    "    \n",
    "    # Map the cluster label to the category name\n",
    "    category = category_names.get(cluster_label, \"Unknown Category\")\n",
    "    return category\n",
    "\n",
    "# Create Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=get_category,\n",
    "    inputs=gr.Textbox(label=\"Enter a Review\"),\n",
    "    outputs=gr.Textbox(label=\"Predicted Category\"),\n",
    "    title=\"Review Categorization\",\n",
    "    description=\"Enter a product review to get a predicted category.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio demo\n",
    "interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO 3 - Clustering + Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nath\\anaconda3\\envs\\ironhack\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator KMeans from version 1.3.0 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* Running on public URL: https://0e7534bee85d31a28f.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0e7534bee85d31a28f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load sentiment analysis model and tokenizer\n",
    "model_path = \"models/distilbert_sa_20241017_193624\"\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sentiment_model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "sentiment_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "\n",
    "# Load clustering model and KMeans\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "kmeans_model_path = \"pickle/KMeans_clustering_model.pkl\"\n",
    "kmeans_model = joblib.load(kmeans_model_path)\n",
    "\n",
    "# Define category names\n",
    "category_names = {\n",
    "    0: \"Electronics & Media\",\n",
    "    1: \"Tablets & eReaders\",\n",
    "    2: \"Accessories & Adapters\",\n",
    "    3: \"Home & Smart Devices\",\n",
    "    4: \"Pet Supplies\",\n",
    "    5: \"Video & Streaming\"\n",
    "}\n",
    "\n",
    "# Prediction functions\n",
    "def get_category(review_text):\n",
    "    # Encode review text and predict the cluster\n",
    "    review_embedding = embedding_model.encode([review_text])\n",
    "    cluster_label = kmeans_model.predict(review_embedding)[0]\n",
    "    category = category_names.get(cluster_label, \"Unknown Category\")\n",
    "    return category\n",
    "\n",
    "def predict_sentiment(review_text):\n",
    "    encodings = tokenizer(review_text, truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\").to(sentiment_model.device)\n",
    "    outputs = sentiment_model(**encodings)\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    probabilities = softmax(outputs.logits, dim=1).squeeze().tolist()\n",
    "    predicted_class = torch.argmax(outputs.logits).item()\n",
    "    \n",
    "    return {label: prob for label, prob in zip(sentiment_labels, probabilities)}\n",
    "\n",
    "# Combined Gradio demo\n",
    "def analyze_review(review_text):\n",
    "    category = get_category(review_text)\n",
    "    sentiment = predict_sentiment(review_text)\n",
    "    return category, sentiment\n",
    "\n",
    "# Set up Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=analyze_review,\n",
    "    inputs=gr.Textbox(label=\"Enter a Review\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Predicted Category\"),\n",
    "        gr.Label(num_top_classes=3, label=\"Sentiment Probabilities\")\n",
    "    ],\n",
    "    title=\"Review Categorization and Sentiment Analysis\",\n",
    "    description=\"Enter a product review to get the predicted category and sentiment analysis with probabilities.\"\n",
    ")\n",
    "\n",
    "# Launch the combined demo\n",
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
