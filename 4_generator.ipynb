{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Generator / Summarizer\n",
    "In this notebook, we implement the 3rd transformer, in charge or generating a review of the best product per category, from a batch of reviews and sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 17:35:19.143212: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-15 17:35:19.143212: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-15 17:35:19.240282: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-15 17:35:19.452168: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-15 17:35:21.993406: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoModelForCausalLM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()  # Initialize tqdm with pandas\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# import helpers module\n",
    "import helpers\n",
    "import importlib\n",
    "importlib.reload(helpers)\n",
    "\n",
    "SEP = 100 * '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load HugginFace token to environment\n",
    "if not os.environ.get('HF_TOKEN'):\n",
    "    os.environ['HF_TOKEN'] = input('Enter API token for Hugging Face: ')\n",
    "else:\n",
    "    print('Hugging Face token already loaded to environment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded from pickle/data_sentiment_analysis.pkl.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[name] Amazon - Amazon Tap Portable Bluetooth and Wi-Fi Speaker - Black,,,\n",
      "Amazon - Amazon Tap Portable Bluetooth and Wi-Fi Speaker - Black,,,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[brand] Amazon\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[categories] Stereos,Remote Controls,Amazon Echo,Audio Docks & Mini Speakers,Amazon Echo Accessories,Kitchen & Dining Features,Speaker Systems,Electronics,TVs Entertainment,Clearance,Smart Hubs & Wireless Routers,Featured Brands,Wireless Speakers,Smart Home & Connected Living,Home Security,Kindle Store,Home Automation,Home, Garage & Office,Home,Voice-Enabled Smart Assistants,Virtual Assistant Speakers,Portable Audio & Headphones,Electronics Features,Amazon Device Accessories,iPod, Audio Player Accessories,Home & Furniture Clearance,Consumer Electronics,Smart Home,Surveillance,Home Improvement,Smart Home & Home Automation Devices,Smart Hubs,Home Safety & Security,Voice Assistants,Alarms & Sensors,Amazon Devices,Audio,Holiday Shop\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[reviews.rating] 5.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[review] very good！！！！！！！！！！！！！！\n",
      "Very goodWas undecided between new PaperWhite and Voyage models and doing a lot of research to see which one is best. Based on some personal analysis on in-store samples, I felt the Voyage has nothing more price worthy than what new PW could offer with lesser $$$. If you are undecided like me, don't worry about the gimmicks of voyage, go for PW..\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[reviews.sentiment] positive\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[reviews.ft] 2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[reviews.ft.sentiment] positive\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data = helpers.load_pickled_dataset('pickle/data_sentiment_analysis.pkl')\n",
    "\n",
    "helpers.print_random_product_sheet(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 1: Prompt Fine-Tuning\n",
    "Let's see what we can get using only prompt fine-tuning. For this I will try [Mistral-7B](https://huggingface.co/mistralai/Mistral-7B-v0.3) in 4bit quantization for quick inference.\n",
    "\n",
    "Using 4-bit quantization will help reduce memory usage significantly while retaining reasonable model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-15 17:38:51.651129: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-15 17:38:51.651220: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-15 17:38:51.653330: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-15 17:38:51.664341: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-15 17:38:53.179161: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "usage: transformers-cli <command> [<args>]\n",
      "Transformers CLI tool: error: argument {convert,download,env,run,serve,login,whoami,logout,repo,add-new-model,add-new-model-like,lfs-enable-largefiles,lfs-multipart-upload,pt-to-tf}: invalid choice: 'cache' (choose from 'convert', 'download', 'env', 'run', 'serve', 'login', 'whoami', 'logout', 'repo', 'add-new-model', 'add-new-model-like', 'lfs-enable-largefiles', 'lfs-multipart-upload', 'pt-to-tf')\n"
     ]
    }
   ],
   "source": [
    "!transformers-cli cache clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Mistral-7b 4bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a80a9c60684ef299e25fceabe92a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my name is Katie and I am a 20 year old student at the University of North Carolina at Chap\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-v0.3\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# load 4bit quantization model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# test model\n",
    "inputs = tokenizer(\"Hello my name is\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template\n",
    "Let's work on a prompt template so the model extract information from reviews and summarize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Summarize the following product review in one sentence, highlighting the main points.\n",
    "Then, provide a list of pros and cons and a short overall conclusion.\n",
    "\n",
    "### Review: \n",
    "{review_text}\n",
    "\n",
    "### One-sentence summary, pros and cons and conclusion:\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the following product review in one sentence, highlighting the main points.\n",
      "Then, provide a list of pros and cons and a short overall conclusion.\n",
      "\n",
      "### Review: \n",
      "This laptop has a fantastic display and long battery life, but the keyboard is a bit cramped, and it tends to get hot during heavy use. Overall, it performs well for everyday tasks and is good value for the price.\n",
      "\n",
      "### One-sentence summary, pros and cons and conclusion:\n",
      "\n",
      "- Pros:\n",
      "  - Fantastic display\n",
      "  - Long battery life\n",
      "  - Good value for the price\n",
      "- Cons:\n",
      "  - Keyboard is a bit cramped\n",
      "  - Tends to get hot during heavy use\n",
      "- Conclusion:\n",
      "  - Performs well for everyday tasks\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_summary(prompt, review):\n",
    "    inputs = tokenizer(prompt.format(review_text=review), return_tensors=\"pt\")\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_new_tokens=100,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    ).to(device)\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "review_text = \"This laptop has a fantastic display and long battery life, but the keyboard is a bit cramped, and it tends to get hot during heavy use. Overall, it performs well for everyday tasks and is good value for the price.\"\n",
    "\n",
    "result = generate_summary(prompt, review_text)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
