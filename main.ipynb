{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face token already loaded to environment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3432ac50c7744fb1bff1c8822e328d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "CATEGORY: Pet Supplies\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TOP PRODUCT NAME: Cat Litter Box Covered Tray Kitten Extra Large Enclosed Hooded Hidden Toilet\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 118\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# review the best product for a given category\u001b[39;00m\n\u001b[1;32m    116\u001b[0m category \u001b[38;5;241m=\u001b[39m categories[\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m review_dict \u001b[38;5;241m=\u001b[39m \u001b[43mreview_best_product_by_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m review_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 58\u001b[0m, in \u001b[0;36mreview_best_product_by_category\u001b[0;34m(model, tokenizer, category, n)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSEP\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTOP PRODUCT NAME: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtop_product_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mSEP\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# get n reviews for the top product\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m sample_reviews \u001b[38;5;241m=\u001b[39m \u001b[43mhelpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_product_reviews\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_product_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSEP\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mINFERENCE 1: SAMPLE OF PRODUCT REVIEWS:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# load review text from pickle if available\u001b[39;00m\n",
      "File \u001b[0;32m/notebooks/helpers.py:319\u001b[0m, in \u001b[0;36msample_product_reviews\u001b[0;34m(name, category, n)\u001b[0m\n\u001b[1;32m    316\u001b[0m positive_n \u001b[38;5;241m=\u001b[39m n \u001b[38;5;241m-\u001b[39m negative_n \u001b[38;5;241m-\u001b[39m neutral_n  \u001b[38;5;66;03m# to sum up to n reviews\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# get reviews for each sentiment\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m positive_reviews \u001b[38;5;241m=\u001b[39m \u001b[43mget_product_reviews_per_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpositive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m neutral_reviews \u001b[38;5;241m=\u001b[39m get_product_reviews_per_sentiment(data, name, category, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m, neutral_n)\n\u001b[1;32m    321\u001b[0m negative_reviews \u001b[38;5;241m=\u001b[39m get_product_reviews_per_sentiment(data, name, category, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m, negative_n)\n",
      "File \u001b[0;32m/notebooks/helpers.py:254\u001b[0m, in \u001b[0;36mget_product_reviews_per_sentiment\u001b[0;34m(data_scored, name, category, sentiment, n)\u001b[0m\n\u001b[1;32m    252\u001b[0m reviews \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(reviews) \u001b[38;5;241m<\u001b[39m n:\n\u001b[0;32m--> 254\u001b[0m     new_review \u001b[38;5;241m=\u001b[39m \u001b[43mget_random_product_review\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# append to list if not already in to avoid duplicates\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_review \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m reviews:\n",
      "File \u001b[0;32m/notebooks/helpers.py:219\u001b[0m, in \u001b[0;36mget_random_product_review\u001b[0;34m(subset, min_word_count)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a cleaned random product review from a subset of the dataset.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    str: A random product review.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# get a random review\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     new_review \u001b[38;5;241m=\u001b[39m \u001b[43msubset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# check if it has enough words\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_review\u001b[38;5;241m.\u001b[39msplit()) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_word_count:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;66;03m# clean the review (forgotten steps in preprocessing)\u001b[39;00m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;66;03m# remove line breaks\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py:6102\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   6099\u001b[0m obj_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m   6101\u001b[0m \u001b[38;5;66;03m# Process random_state argument\u001b[39;00m\n\u001b[0;32m-> 6102\u001b[0m rs \u001b[38;5;241m=\u001b[39m \u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6104\u001b[0m size \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mprocess_sampling_size(n, frac, replace)\n\u001b[1;32m   6105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/common.py:452\u001b[0m, in \u001b[0;36mrandom_state\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03mHelper function for processing random_state arguments.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(state) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mBitGenerator)):\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRandomState\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state, np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState):\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:184\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mt19937.pyx:132\u001b[0m, in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "File Name: main.py\n",
    "Author: Alexandre Donciu-Julin\n",
    "Date: 2024-10-14\n",
    "Description: Main file to run inference on the model.\n",
    "\"\"\"\n",
    "\n",
    "# load custom modules ------------------------------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import helpers\n",
    "import prompting\n",
    "importlib.reload(helpers)\n",
    "importlib.reload(prompting)\n",
    "\n",
    "# constants and paths ------------------------------------------------------------------------------\n",
    "DATA_PROCESSED_PKL = 'pickle/data_processed.pkl'\n",
    "DATA_CLUSTERED_PKL = 'pickle/data_clustered.pkl'\n",
    "DATA_SA_PKL = 'pickle/data_sentiment_analysis.pkl'\n",
    "DATA_SCORED_PKL = 'pickle/data_scored.pkl'\n",
    "SEP = 100 * '-'\n",
    "\n",
    "# global variables ---------------------------------------------------------------------------------\n",
    "# to avoid loading the model and tokenizer multiple times\n",
    "model = None\n",
    "tokenizer = None\n",
    "\n",
    "\n",
    "def review_best_product_by_category(\n",
    "        model: object,\n",
    "        tokenizer: object,\n",
    "        category: str,\n",
    "        n: int = 10\n",
    ") -> dict:\n",
    "    \"\"\"Review the best product in a category based on n reviews.\n",
    "\n",
    "    Args:\n",
    "        model (object): The model instance to use for inference.\n",
    "        tokenizer (object): The tokenizer instance to use for inference.\n",
    "        category (str): The category to extract the best product from.\n",
    "        n (int, optional): Number of reviews to use for the final review. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        str: The full review packed inside a dict.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"{SEP}\\nCATEGORY: {category}\")\n",
    "    \n",
    "    # get the name of the top product in the category\n",
    "    top_product_name = helpers.get_top_products_per_category(category, 1)[0]\n",
    "    print(f\"{SEP}\\nTOP PRODUCT NAME: {top_product_name}\\n{SEP}\")\n",
    "    \n",
    "    # get n reviews for the top product\n",
    "    sample_reviews = helpers.sample_product_reviews(top_product_name, category, n)\n",
    "\n",
    "    print(f\"{SEP}\\nINFERENCE 1: SAMPLE OF PRODUCT REVIEWS:\\n\")\n",
    "\n",
    "    # load review text from pickle if available\n",
    "    pickle_path = os.path.join('pickle', f\"reviews_{category.lower().replace(' ', '_')}.pkl\")\n",
    "\n",
    "    if os.path.exists(pickle_path):\n",
    "        review_text = helpers.load_pickled_reviews(pickle_path)\n",
    "        print(f\"{review_text}\")\n",
    "\n",
    "    else:\n",
    "        # summarize all reviews and build review_text\n",
    "        review_text = \"\"\n",
    "        for i, review in enumerate(sample_reviews):\n",
    "            # infer model and summarize review\n",
    "            review_summary = f\"[Review {i + 1}]: {prompting.generate_review_summary(model, tokenizer, review)}\"\n",
    "            print(review_summary)\n",
    "            review_text += review_summary + '\\n'\n",
    "\n",
    "        # pickle the review text\n",
    "        helpers.pickle_list_reviews(review_text, pickle_path)\n",
    "\n",
    "    # generate recurring ideas\n",
    "    recurring_ideas = prompting.generate_reviews_recurring_ideas(model, tokenizer, review_text, max_tokens=75)\n",
    "    print(f\"{SEP}\\nINFERENCE 2: RECURRING IDEAS:\\n\\n{recurring_ideas}\")\n",
    "\n",
    "    # generate final review\n",
    "    review_title, product_review = prompting.generate_final_review(model, tokenizer, top_product_name, recurring_ideas, max_tokens=150)\n",
    "    print(f\"{SEP}\\nINFERENCE 3: FINAL REVIEW:\\n\")\n",
    "\n",
    "    review_dict = {}\n",
    "    review_dict[\"category\"] = category\n",
    "    review_dict[\"product\"] = top_product_name\n",
    "    review_dict[\"title\"] = review_title\n",
    "    review_dict[\"review\"] = product_review\n",
    "\n",
    "    return review_dict\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # load HugginFace token to environment\n",
    "    if not os.environ.get('HF_TOKEN'):\n",
    "        os.environ['HF_TOKEN'] = input('Enter API token for Hugging Face: ')\n",
    "    else:\n",
    "        print('Hugging Face token already loaded to environment')\n",
    "\n",
    "    # load the model and tokenizer\n",
    "    if model is None and tokenizer is None:\n",
    "        model, tokenizer = prompting.load_model_and_tokenizer()\n",
    "    else:\n",
    "        print('Model and tokenizer already loaded')\n",
    "\n",
    "    # get the unique categories\n",
    "    categories = helpers.get_categories_from_dataset()\n",
    "\n",
    "    # review the best product for a given category\n",
    "    category = categories[3]\n",
    "\n",
    "    review_dict = review_best_product_by_category(model, tokenizer, category)\n",
    "\n",
    "    for k, v in review_dict.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
